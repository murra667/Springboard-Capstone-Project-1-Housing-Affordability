

listings_pages = [str(i) for i in range(120, 2280)]

from time import sleep 
from random import randint
from time import time 

start_time = time()
requests = 0


import requests
from requests import get
from warnings import warn 
from bs4 import BeautifulSoup

from IPython.core.display import clear_output
page = requests.get("https://minneapolis.craigslist.org/search/apa")
soup = BeautifulSoup(page.content, 'html.parser')
start_time = time()
requests = 0

for page in listings_pages: 
    
    response = get("https://minneapolis.craigslist.org/search/apa?s=" + listings_pages)
    sleep(randint(8,15))
    requests += 1 
    elapsed_time = time() - start_time
    print ("Request: {}; Frequency: {} request/s".format(requests, requests/elapsed_time))
    clear_output(wait = True)
    
    if response.status_code !=200:
        warn('Request: {}; Status code: {}'.form)
    if requests > 120:
        warn('Number of requests was greater than 120')
        break
    
    soup = BeautifulSoup(page.text, 'html.parser')
    listing_containers = soup.find_all('li', class_="result-row")
    
    for container in listing_containers:
    # prices
        price = container.span.text
        prices.append(price)
    # titles
        title = container.p.find('a', class_="result-title hdrlnk").text
        titles.append(title)
    
    # ids
        id_ = container.p.find('a', class_="result-title hdrlnk")['data-id']
        ids.append(id_)
    
    # datetime
        datetime = container.time['datetime']
        datetimes.append(datetime)
